{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dimas0824/Machine_Learning/blob/main/Jobsheet_13/ML_WEEK13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAKP1bETjdAK"
      },
      "source": [
        "# TUGAS PRAKTIKUM\n",
        "\n",
        "Gunakan JST untuk klasifikasi angka tulisan tangan (MNIST).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oJt-gvVijeRZ",
        "outputId": "350a2cbf-9a01-4238-a993-b440afef76b5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8744 - loss: 0.4270 - val_accuracy: 0.9661 - val_loss: 0.1114\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9676 - loss: 0.1067 - val_accuracy: 0.9735 - val_loss: 0.0854\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9773 - loss: 0.0709 - val_accuracy: 0.9724 - val_loss: 0.0856\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9839 - loss: 0.0522 - val_accuracy: 0.9762 - val_loss: 0.0793\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9874 - loss: 0.0392 - val_accuracy: 0.9759 - val_loss: 0.0808\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9902 - loss: 0.0307 - val_accuracy: 0.9777 - val_loss: 0.0779\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9915 - loss: 0.0260 - val_accuracy: 0.9748 - val_loss: 0.0909\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9932 - loss: 0.0205 - val_accuracy: 0.9794 - val_loss: 0.0812\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9942 - loss: 0.0173 - val_accuracy: 0.9770 - val_loss: 0.0972\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9941 - loss: 0.0174 - val_accuracy: 0.9780 - val_loss: 0.0930\n",
            "Akurasi pada data uji: 0.9780\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 1. Load dataset MNIST\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalisasi data (0-255 → 0-1)\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# One-hot encoding label\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# 2. Bangun model JST\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)), # Ubah gambar 28x28 menjadi vektor\n",
        "    Dense(128, activation='relu'), # Hidden layer 1\n",
        "    Dense(64, activation='relu'),  # Hidden layer 2\n",
        "    Dense(10, activation='softmax') # Output layer (10 kelas)\n",
        "])\n",
        "\n",
        "# 3. Kompilasi model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 4. Latih model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# 5. Evaluasi model\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Akurasi pada data uji: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UhIAHV4zZUj"
      },
      "source": [
        "## Coba dengan beberapa parameter lain:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwFhdBVwzpJ_"
      },
      "source": [
        "### Ubah jumlah neuron di hidden layer (misal: 256 dan 128).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qu--zO7mznVC",
        "outputId": "26073f02-603c-47f4-9ec3-85328fa4035e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.8928 - loss: 0.3595 - val_accuracy: 0.9616 - val_loss: 0.1274\n",
            "Epoch 2/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9742 - loss: 0.0837 - val_accuracy: 0.9737 - val_loss: 0.0876\n",
            "Epoch 3/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9816 - loss: 0.0579 - val_accuracy: 0.9777 - val_loss: 0.0732\n",
            "Epoch 4/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9866 - loss: 0.0419 - val_accuracy: 0.9759 - val_loss: 0.0820\n",
            "Epoch 5/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9908 - loss: 0.0296 - val_accuracy: 0.9814 - val_loss: 0.0697\n",
            "Epoch 6/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9913 - loss: 0.0262 - val_accuracy: 0.9742 - val_loss: 0.1004\n",
            "Epoch 7/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9928 - loss: 0.0220 - val_accuracy: 0.9770 - val_loss: 0.0882\n",
            "Epoch 8/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9939 - loss: 0.0184 - val_accuracy: 0.9815 - val_loss: 0.0735\n",
            "Epoch 9/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9955 - loss: 0.0134 - val_accuracy: 0.9787 - val_loss: 0.0942\n",
            "Epoch 10/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9952 - loss: 0.0148 - val_accuracy: 0.9784 - val_loss: 0.0942\n",
            "Epoch 11/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9956 - loss: 0.0134 - val_accuracy: 0.9778 - val_loss: 0.0979\n",
            "Epoch 12/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9965 - loss: 0.0106 - val_accuracy: 0.9776 - val_loss: 0.0920\n",
            "Epoch 13/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9959 - loss: 0.0132 - val_accuracy: 0.9805 - val_loss: 0.0991\n",
            "Epoch 14/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9963 - loss: 0.0110 - val_accuracy: 0.9802 - val_loss: 0.1025\n",
            "Epoch 15/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9964 - loss: 0.0113 - val_accuracy: 0.9806 - val_loss: 0.1045\n",
            "Akurasi pada data uji: 0.9814\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# 1. Load dataset MNIST\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalisasi data (0-255 → 0-1)\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# One-hot encoding label\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# 2. Model JST\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# 3. Kompilasi\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 4. Early Stopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',   # berhenti jika val_loss tidak membaik\n",
        "    patience=10,           # toleransi 10 epoch\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# 5. Latih model (banyak epoch)\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=50,             # epoch lebih besar\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "# 6. Evaluasi\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Akurasi pada data uji: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4JN3xsxzxi1"
      },
      "source": [
        "### Tambahkan satu hidden layer lagi.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7Nh6YQHzzAl",
        "outputId": "68f99813-f395-4386-9697-96595ecbc338"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.8886 - loss: 0.3719 - val_accuracy: 0.9648 - val_loss: 0.1131\n",
            "Epoch 2/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9735 - loss: 0.0888 - val_accuracy: 0.9748 - val_loss: 0.0834\n",
            "Epoch 3/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9811 - loss: 0.0602 - val_accuracy: 0.9768 - val_loss: 0.0817\n",
            "Epoch 4/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9849 - loss: 0.0471 - val_accuracy: 0.9784 - val_loss: 0.0732\n",
            "Epoch 5/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9874 - loss: 0.0382 - val_accuracy: 0.9758 - val_loss: 0.0864\n",
            "Epoch 6/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9887 - loss: 0.0342 - val_accuracy: 0.9741 - val_loss: 0.0950\n",
            "Epoch 7/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9920 - loss: 0.0235 - val_accuracy: 0.9763 - val_loss: 0.0918\n",
            "Epoch 8/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.9931 - loss: 0.0210 - val_accuracy: 0.9786 - val_loss: 0.0846\n",
            "Epoch 9/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9934 - loss: 0.0206 - val_accuracy: 0.9749 - val_loss: 0.1051\n",
            "Epoch 10/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9939 - loss: 0.0180 - val_accuracy: 0.9807 - val_loss: 0.0869\n",
            "Epoch 11/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9944 - loss: 0.0179 - val_accuracy: 0.9759 - val_loss: 0.1073\n",
            "Epoch 12/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9955 - loss: 0.0146 - val_accuracy: 0.9815 - val_loss: 0.0832\n",
            "Epoch 13/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9966 - loss: 0.0126 - val_accuracy: 0.9795 - val_loss: 0.0996\n",
            "Epoch 14/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9952 - loss: 0.0157 - val_accuracy: 0.9826 - val_loss: 0.0890\n",
            "Akurasi pada data uji: 0.9784\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# 1. Load dataset MNIST\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalisasi data (0-255 → 0-1)\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# One-hot encoding label\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# 2. Model JST\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)), # flatten image dari 28x28 menjadi vektor\n",
        "    Dense(256, activation='relu'), # Hidden layer 1\n",
        "    Dense(128, activation='relu'), # Hidden layer 2\n",
        "    Dense(64, activation='relu'), # Hidden layer 3\n",
        "    Dense(10, activation='softmax') # Output layer (10 kelas)\n",
        "])\n",
        "\n",
        "# 3. Kompilasi\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 4. Early Stopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',   # berhenti jika val_loss tidak membaik\n",
        "    patience=10,           # toleransi 10 epoch\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# 5. Latih model (banyak epoch)\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=50,             # epoch lebih besar\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "# 6. Evaluasi\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Akurasi pada data uji: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZegx1PQz5V1"
      },
      "source": [
        "### Bandingkan akurasi dan waktu pelatihan.\n",
        "\n",
        "Perbandingan Dua Model JST MNIST\n",
        "\n",
        "| Aspek | Model 1 (256→128→Softmax) | Model 2 (256→128→64→Softmax) |\n",
        "|------|---------------------------|-------------------------------|\n",
        "| Jumlah Hidden Layer | 2 | 3 |\n",
        "| Val Loss Terbaik | 0.0697 | 0.0732 |\n",
        "| Val Accuracy Terbaik | 0.9815 | 0.9826 |\n",
        "| Akurasi Akhir Test | **0.9814** | **0.9784** |\n",
        "| Rata-rata Waktu per Epoch | ~12.5 detik | ~13.5 detik |\n",
        "| Total Epoch (Early Stop) | 15 | 14 |\n",
        "| Total Waktu Komputasi | ±187 detik (3 menit 7 detik) | ±189 detik (3 menit 9 detik) |\n",
        "| Efisiensi Latihan | Lebih efisien | Sedikit lebih lambat |\n",
        "| Risiko Overfitting | Lebih rendah | Lebih tinggi |\n",
        "\n",
        "\n",
        "\n",
        "Model kedua memiliki arsitektur yang lebih dalam, sehingga jumlah parameternya lebih banyak. Untuk dataset sederhana seperti MNIST, kapasitas model yang terlalu besar menyebabkan overfitting lebih cepat, di mana model belajar pola yang tidak relevan dan kehilangan kemampuan generalisasi pada data uji. Selain itu, penambahan layer tambahan tidak memberikan informasi baru yang signifikan bagi MLP untuk gambar sederhana 28×28, sehingga justru membuat proses pelatihan lebih tidak stabil dan membutuhkan waktu komputasi lebih lama.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_d1A76rz7oC"
      },
      "source": [
        "### Eksperimen dengan fungsi aktivasi Sigmoid vs ReLU.\n",
        "\n",
        "Model sigmoid masih menghasilkan akurasi tinggi, namun tetap sedikit di bawah ReLU karena sigmoid lebih rentan mengalami vanishing gradient, sehingga proses belajar lebih lambat dan kadang berhenti di titik suboptimal. Secara waktu, sigmoid juga lebih lambat karena fungsi aktivasi sigmoid membutuhkan komputasi eksponensial.\n",
        "\n",
        " Perbandingan Model ReLU vs Sigmoid (Arsitektur Sama)\n",
        "\n",
        "| Aspek | Model ReLU (256→128) | Model Sigmoid (256→128) |\n",
        "|------|-----------------------|---------------------------|\n",
        "| Aktivasi Hidden Layer | ReLU | Sigmoid |\n",
        "| Epoch Total (Early Stop) | 15 | 19 |\n",
        "| Val Loss Terbaik | **0.0697** | **0.0680** |\n",
        "| Val Accuracy Terbaik | **0.9815** | **0.9816** |\n",
        "| Akurasi Akhir Test | **0.9814** | **0.9812** |\n",
        "| Rata-rata Waktu per Epoch | ~12.5 detik | ~13.5 detik |\n",
        "| Total Waktu Pelatihan | ±187 detik | ±256 detik |\n",
        "| Kecepatan Konvergensi | Lebih cepat | Lebih lambat |\n",
        "| Risiko Vanishing Gradient | Rendah | Lebih tinggi |\n",
        "| Kompleksitas Komputasi | Ringan | Lebih berat (fungsi sigmoid) |\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyBHcNsvz7D-",
        "outputId": "e34ab8da-618b-46a4-bf4d-e171cf1e97b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.8054 - loss: 0.7042 - val_accuracy: 0.9432 - val_loss: 0.1885\n",
            "Epoch 2/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9494 - loss: 0.1700 - val_accuracy: 0.9594 - val_loss: 0.1329\n",
            "Epoch 3/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9672 - loss: 0.1102 - val_accuracy: 0.9665 - val_loss: 0.1012\n",
            "Epoch 4/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9773 - loss: 0.0750 - val_accuracy: 0.9736 - val_loss: 0.0830\n",
            "Epoch 5/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9837 - loss: 0.0575 - val_accuracy: 0.9765 - val_loss: 0.0733\n",
            "Epoch 6/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9876 - loss: 0.0414 - val_accuracy: 0.9769 - val_loss: 0.0750\n",
            "Epoch 7/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9903 - loss: 0.0314 - val_accuracy: 0.9769 - val_loss: 0.0756\n",
            "Epoch 8/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9937 - loss: 0.0219 - val_accuracy: 0.9797 - val_loss: 0.0696\n",
            "Epoch 9/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9951 - loss: 0.0169 - val_accuracy: 0.9812 - val_loss: 0.0680\n",
            "Epoch 10/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9965 - loss: 0.0123 - val_accuracy: 0.9757 - val_loss: 0.0816\n",
            "Epoch 11/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9965 - loss: 0.0116 - val_accuracy: 0.9802 - val_loss: 0.0704\n",
            "Epoch 12/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0080 - val_accuracy: 0.9802 - val_loss: 0.0765\n",
            "Epoch 13/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9986 - loss: 0.0059 - val_accuracy: 0.9811 - val_loss: 0.0797\n",
            "Epoch 14/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0053 - val_accuracy: 0.9799 - val_loss: 0.0817\n",
            "Epoch 15/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0051 - val_accuracy: 0.9806 - val_loss: 0.0841\n",
            "Epoch 16/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0051 - val_accuracy: 0.9816 - val_loss: 0.0800\n",
            "Epoch 17/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0024 - val_accuracy: 0.9801 - val_loss: 0.0869\n",
            "Epoch 18/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0028 - val_accuracy: 0.9709 - val_loss: 0.1340\n",
            "Epoch 19/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9989 - loss: 0.0037 - val_accuracy: 0.9812 - val_loss: 0.0899\n",
            "Akurasi pada data uji: 0.9812\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# 1. Load dataset MNIST\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalisasi data (0-255 → 0-1)\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# One-hot encoding label\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# 2. Model JST\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)), # flatten image dari 28x28 menjadi vektor\n",
        "    Dense(256, activation='sigmoid'), # Hidden layer 1\n",
        "    Dense(128, activation='sigmoid'), # Hidden layer 2\n",
        "    Dense(10, activation='softmax') # Output layer (10 kelas)\n",
        "])\n",
        "\n",
        "# 3. Kompilasi\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 4. Early Stopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',   # berhenti jika val_loss tidak membaik\n",
        "    patience=10,           # toleransi 10 epoch\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# 5. Latih model (banyak epoch)\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=50,             # epoch lebih besar\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "# 6. Evaluasi\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Akurasi pada data uji: {acc:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyO9AeBe5MlgI/sEHv2Kwc+j",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
